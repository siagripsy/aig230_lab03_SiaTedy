{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91489c36",
   "metadata": {},
   "source": [
    "# AIG230 NLP (Week 3 Lab) â€” Notebook 2: Statistical Language Models (Train, Test, Evaluate)\n",
    "\n",
    "This notebook focuses on **n-gram Statistical Language Models (SLMs)**:\n",
    "- Train **unigram**, **bigram**, **trigram** models\n",
    "- Handle **OOV** with `<UNK>`\n",
    "- Apply **smoothing** (Add-k)\n",
    "- Evaluate with **cross-entropy** and **perplexity**\n",
    "- Do **next-word prediction** and simple **text generation**\n",
    "\n",
    "> Industry framing: even if modern systems use neural LMs, n-gram LMs are still useful for\n",
    "baselines, constrained domains, and for understanding evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a046e",
   "metadata": {},
   "source": [
    "## 0) Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ee526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple, Dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc428b4",
   "metadata": {},
   "source": [
    "## 1) Data: domain text you might see in real systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d207e4c",
   "metadata": {},
   "source": [
    "We use short texts that resemble:\n",
    "- release notes\n",
    "- incident summaries\n",
    "- operational runbooks\n",
    "- customer support messaging\n",
    "\n",
    "In practice, you would load thousands to millions of lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb34582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " 4,\n",
       " ['printer driver install fails with error 1603',\n",
       "  'push notifications not working on android app'],\n",
       " ['email delivery delayed messages queued',\n",
       "  'vpn disconnects frequently after windows update'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "corpus = [\n",
    "    \"vpn disconnects frequently after windows update\",\n",
    "    \"password reset link expired user cannot login\",\n",
    "    \"api requests timeout when latency spikes\",\n",
    "    \"portal returns 500 error after deployment\",\n",
    "    \"email delivery delayed messages queued\",\n",
    "    \"mfa prompt never arrives user stuck at login\",\n",
    "    \"wifi drops in meeting rooms access point reboot helps\",\n",
    "    \"outlook search not returning results index corrupted\",\n",
    "    \"printer driver install fails with error 1603\",\n",
    "    \"teams calls choppy audio jitter high\",\n",
    "    \"permission denied accessing shared drive though in correct group\",\n",
    "    \"battery drains fast after bios update power settings unchanged\",\n",
    "    \"push notifications not working on android app\",\n",
    "    \"mailbox full cannot receive emails auto archive not running\",\n",
    "]\n",
    "\n",
    "# Train/test split at sentence level\n",
    "random.seed(42)\n",
    "random.shuffle(corpus)\n",
    "split = int(0.75 * len(corpus))\n",
    "train_texts = corpus[:split]\n",
    "test_texts = corpus[split:]\n",
    "\n",
    "len(train_texts), len(test_texts), train_texts[:2], test_texts[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f9947",
   "metadata": {},
   "source": [
    "## 2) Tokenization + special tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c285f1d",
   "metadata": {},
   "source": [
    "We will:\n",
    "- lowercase\n",
    "- keep alphanumerics\n",
    "- split on whitespace\n",
    "- add sentence boundary tokens: `<s>` and `</s>`\n",
    "\n",
    "We will also map rare tokens to `<UNK>` based on training frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058f87da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<s>',\n",
       " 'printer',\n",
       " 'driver',\n",
       " 'install',\n",
       " 'fails',\n",
       " 'with',\n",
       " 'error',\n",
       " '1603',\n",
       " '</s>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text.split()\n",
    "\n",
    "def add_boundaries(tokens: List[str], n: int) -> List[str]:\n",
    "    # For n-grams, prepend (n-1) start tokens for simpler context handling\n",
    "    return [\"<s>\"]*(n-1) + tokens + [\"</s>\"]\n",
    "\n",
    "# Example\n",
    "tokens = tokenize(\"Printer driver install fails with error 1603\")\n",
    "add_boundaries(tokens, n=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25308557",
   "metadata": {},
   "source": [
    "## 3) Build vocabulary and handle OOV with <UNK>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3338f0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['email', 'delivery', 'delayed', 'messages', 'queued'],\n",
       " ['<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Build vocab from training data\n",
    "train_tokens_flat = []\n",
    "for t in train_texts:\n",
    "    train_tokens_flat.extend(tokenize(t))\n",
    "\n",
    "freq = Counter(train_tokens_flat)\n",
    "\n",
    "# Typical practical rule: map tokens with frequency <= 1 to <UNK> in small corpora\n",
    "min_count = 2\n",
    "vocab = {w for w, c in freq.items() if c >= min_count}\n",
    "vocab |= {\"<UNK>\", \"<s>\", \"</s>\"}\n",
    "\n",
    "def replace_oov(tokens: List[str], vocab: set) -> List[str]:\n",
    "    return [tok if tok in vocab else \"<UNK>\" for tok in tokens]\n",
    "\n",
    "# Show OOV effect\n",
    "sample = tokenize(test_texts[0])\n",
    "sample, replace_oov(sample, vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759444a0",
   "metadata": {},
   "source": [
    "## 4) Train n-gram counts (unigram, bigram, trigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eac8fa",
   "metadata": {},
   "source": [
    "We will compute:\n",
    "- `ngram_counts[(w1,...,wn)]`\n",
    "- `context_counts[(w1,...,w_{n-1})]`\n",
    "\n",
    "Then probability:\n",
    "\\ndefault:  P(w_n | context) = count(context + w_n) / count(context)\n",
    "\n",
    "This fails when an n-gram is unseen, so we add smoothing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33672bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(tokens: List[str], n: int) -> List[Tuple[str, ...]]:\n",
    "    return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "\n",
    "def train_ngram_counts(texts: list[str], n: int, vocab: set) -> Dict[Tuple[str, ...], int]:\n",
    "    ngram_counts = Counter()\n",
    "    context_counts = Counter()\n",
    "    for text in texts:\n",
    "        tokens = replace_oov(tokenize(text),vocab)\n",
    "        tokens = add_boundaries(tokens, n)\n",
    "        for ng in get_ngrams(tokens, n):\n",
    "            ngram_counts[ng] += 1\n",
    "            context = ng[:-1]\n",
    "            context_counts[context] += 1\n",
    "    return ngram_counts, context_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46645a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_counts, uni_contexts  = train_ngram_counts(train_texts, 1, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9700d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('<UNK>',): 67,\n",
       "         ('</s>',): 10,\n",
       "         ('not',): 3,\n",
       "         ('error',): 2,\n",
       "         ('after',): 2})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4eedde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('<UNK>', '<UNK>'): 51,\n",
       "         ('<s>', '<UNK>'): 10,\n",
       "         ('<UNK>', '</s>'): 10,\n",
       "         ('<UNK>', 'not'): 3,\n",
       "         ('not', '<UNK>'): 3,\n",
       "         ('<UNK>', 'error'): 2,\n",
       "         ('after', '<UNK>'): 2,\n",
       "         ('error', '<UNK>'): 1,\n",
       "         ('<UNK>', 'after'): 1,\n",
       "         ('error', 'after'): 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_counts , bi_ctx = train_ngram_counts(train_texts, 2, vocab)\n",
    "bi_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11b3e9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('<UNK>', '<UNK>', '<UNK>'): 38,\n",
       "         ('<s>', '<s>', '<UNK>'): 10,\n",
       "         ('<s>', '<UNK>', '<UNK>'): 10,\n",
       "         ('<UNK>', '<UNK>', '</s>'): 7,\n",
       "         ('<UNK>', '<UNK>', 'not'): 3,\n",
       "         ('<UNK>', 'not', '<UNK>'): 3,\n",
       "         ('<UNK>', '<UNK>', 'error'): 2,\n",
       "         ('not', '<UNK>', '<UNK>'): 2,\n",
       "         ('<UNK>', 'error', '<UNK>'): 1,\n",
       "         ('error', '<UNK>', '</s>'): 1,\n",
       "         ('not', '<UNK>', '</s>'): 1,\n",
       "         ('<UNK>', '<UNK>', 'after'): 1,\n",
       "         ('<UNK>', 'after', '<UNK>'): 1,\n",
       "         ('after', '<UNK>', '<UNK>'): 1,\n",
       "         ('<UNK>', 'error', 'after'): 1,\n",
       "         ('error', 'after', '<UNK>'): 1,\n",
       "         ('after', '<UNK>', '</s>'): 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_counts, tri_ctx = train_ngram_counts(train_texts, 3, vocab)\n",
    "tri_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ba7c8",
   "metadata": {},
   "source": [
    "## 5) Add-k smoothing and probability function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed806986",
   "metadata": {},
   "source": [
    "Add-k smoothing (a common baseline):\n",
    "\\na) Add *k* to every possible next word count  \n",
    "b) Normalize by context_count + k * |V|\n",
    "\n",
    "P_k(w|h) = (count(h,w) + k) / (count(h) + k*|V|)\n",
    "\n",
    "Where V is the vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de565994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_addk(ngram: Tuple[str, ...], ngram_counts: Counter,context_counts:Counter, V: int, k: float = 0.5) -> float:\n",
    "    \"\"\"\n",
    "    Compute add-k P(w_n| w_1 ... w_{n-1})\n",
    "    where ngram = (w_1, w_2, ... , w_n)\n",
    "    0 < k < = 1\n",
    "    V is the vocabulary size\n",
    "    \"\"\"\n",
    "    context = ngram[:-1]\n",
    "    return (ngram_counts[ngram] + k) / (context_counts[context] + k*V)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63bf536d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038461538461538464"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = len(vocab)\n",
    "example = ( \"<s>\", \"login\")\n",
    "prob_addk(example, bi_counts, bi_ctx, V, k=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6deec",
   "metadata": {},
   "source": [
    "## 6) Evaluate: cross-entropy and perplexity on test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8426d9",
   "metadata": {},
   "source": [
    "We evaluate an LM by how well it predicts held-out text.\n",
    "\n",
    "Cross-entropy (average negative log probability):\n",
    "H = - (1/N) * sum log2 P(w_i | context)\n",
    "\n",
    "Perplexity:\n",
    "PP = 2^H\n",
    "\n",
    "Lower perplexity is better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2d03099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_perplexity(texts: List[str], n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, k: float = 0.5) -> float:\n",
    "\n",
    "    V = len(vocab)\n",
    "    log2_probs = []\n",
    "    token_counts = 0\n",
    "    for text in texts:\n",
    "        tokens = replace_oov(tokenize(text),vocab)\n",
    "        tokens = add_boundaries(tokens, n)\n",
    "        ngrams = get_ngrams(tokens, n)\n",
    "        for ng in ngrams:\n",
    "            prob = prob_addk(ng, ngram_counts, context_counts, V, k)\n",
    "            log2_probs.append(math.log(prob,2))\n",
    "            token_counts += 1\n",
    "    H = -sum(log2_probs) / token_counts\n",
    "    PP = 2 ** H\n",
    "    return PP\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65f3ad9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8224739937573902, 1.8712095221558307, 1.9552746520172761)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_uni = evaluate_perplexity(test_texts, 1, uni_counts, uni_contexts, vocab, k=0.5)\n",
    "pp_bi = evaluate_perplexity(test_texts, 2, bi_counts, bi_ctx, vocab, k=0.5)\n",
    "pp_tri = evaluate_perplexity(test_texts, 3, tri_counts, tri_ctx, vocab, k=0.5)\n",
    "\n",
    "pp_uni, pp_bi, pp_tri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef338ce",
   "metadata": {},
   "source": [
    "## 7) Next-word prediction (top-k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d202f5",
   "metadata": {},
   "source": [
    "Given a context, compute the probability of each candidate next token and return the top-k.\n",
    "\n",
    "This mirrors:\n",
    "- autocomplete in constrained domains\n",
    "- template suggestion systems\n",
    "- command prediction in runbooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11363d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<UNK>', 0.8076923076923077),\n",
       " ('not', 0.038461538461538464),\n",
       " ('</s>', 0.038461538461538464),\n",
       " ('after', 0.038461538461538464),\n",
       " ('error', 0.038461538461538464)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def next_word_topk(context_tokens: List[str], n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, k_smooth: float = 0.5, top_k: int = 5):\n",
    "    # Context length should be n-1\n",
    "    V = len(vocab)\n",
    "    context = tuple(context_tokens[-(n-1):]) if n > 1 else tuple()\n",
    "    candidates = []\n",
    "    for w in vocab:\n",
    "        if w in {\"<s>\"}:\n",
    "            continue\n",
    "        ng = context + (w,)\n",
    "        p = prob_addk(ng, ngram_counts, context_counts, V, k=k_smooth)\n",
    "        candidates.append((w, p))\n",
    "    candidates.sort(key=lambda x: -x[1])\n",
    "    return candidates[:top_k]\n",
    "\n",
    "# Bigram: context is 1 token\n",
    "next_word_topk([\"<s>\"], n=2, ngram_counts=bi_counts, context_counts=bi_ctx, vocab=vocab, top_k=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672e1e9",
   "metadata": {},
   "source": [
    "## 8) Simple generation (bigram or trigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd41fb",
   "metadata": {},
   "source": [
    "Text generation is not the main goal in SLMs, but it helps you verify:\n",
    "- boundary handling\n",
    "- smoothing\n",
    "- OOV decisions\n",
    "\n",
    "We will sample tokens until we hit `</s>`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c8d1acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIGRAM: not\n",
      "BIGRAM: <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n",
      "BIGRAM: <UNK> <UNK> after <UNK>\n",
      "BIGRAM: <UNK> <UNK> <UNK> <UNK> not <UNK>\n",
      "BIGRAM: <UNK>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sample_next(context_tokens: List[str], n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, k_smooth: float = 0.5):\n",
    "    V = len(vocab)\n",
    "    context = tuple(context_tokens[-(n-1):]) if n > 1 else tuple()\n",
    "    words = [w for w in vocab if w != \"<s>\"]\n",
    "    probs = []\n",
    "    for w in words:\n",
    "        ng = context + (w,)\n",
    "        probs.append(prob_addk(ng, ngram_counts, context_counts, V, k=k_smooth))\n",
    "    # Normalize\n",
    "    s = sum(probs)\n",
    "    probs = [p/s for p in probs]\n",
    "    return random.choices(words, weights=probs, k=1)[0]\n",
    "\n",
    "def generate(n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, max_len: int = 20, k_smooth: float = 0.5):\n",
    "    tokens = [\"<s>\"]*(n-1) if n > 1 else []\n",
    "    out = []\n",
    "    for _ in range(max_len):\n",
    "        w = sample_next(tokens, n, ngram_counts, context_counts, vocab, k_smooth=k_smooth)\n",
    "        if w == \"</s>\":\n",
    "            break\n",
    "        out.append(w)\n",
    "        tokens.append(w)\n",
    "    return \" \".join(out)\n",
    "\n",
    "for _ in range(5):\n",
    "    print(\"BIGRAM:\", generate(2, bi_counts, bi_ctx, vocab, max_len=18))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db5405",
   "metadata": {},
   "source": [
    "## 9) Model comparison: effect of n and smoothing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7486afd",
   "metadata": {},
   "source": [
    "Try different `k` values. Notes:\n",
    "- `k=1.0` is Laplace smoothing (often too strong)\n",
    "- smaller `k` (like 0.1 to 0.5) is often better\n",
    "\n",
    "In real corpora, trigrams often beat bigrams, but require more data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eb25609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1.0:  bigram PP=1.95   trigram PP=2.09\n",
      "k= 0.5:  bigram PP=1.87   trigram PP=1.96\n",
      "k= 0.1:  bigram PP=1.79   trigram PP=1.80\n",
      "k=0.01:  bigram PP=1.76   trigram PP=1.75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in [1.0, 0.5, 0.1, 0.01]:\n",
    "    pp_bi_k  = evaluate_perplexity(test_texts, n=2, ngram_counts=bi_counts,  context_counts=bi_ctx,  vocab=vocab, k=k)\n",
    "    pp_tri_k = evaluate_perplexity(test_texts, n=3, ngram_counts=tri_counts, context_counts=tri_ctx, vocab=vocab, k=k)\n",
    "    print(f\"k={k:>4}:  bigram PP={pp_bi_k:,.2f}   trigram PP={pp_tri_k:,.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be49abe",
   "metadata": {},
   "source": [
    "## Exercises (do these during lab)\n",
    "1) Add 20 more realistic domain sentences to the corpus and re-run training/evaluation.  \n",
    "2) Change `min_count` (OOV threshold) and explain how perplexity changes.  \n",
    "3) Implement **backoff**: if a trigram is unseen, fall back to bigram; if unseen, fall back to unigram.  \n",
    "4) Create a function that returns **top-5 next words** given a phrase like: `\"user cannot\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7bec73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193.5384198636684, 158.84278982001533, 163.72100037353383)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====== Exercise 1: Expand corpus + retrain + re-evaluate ======\n",
    "\n",
    "import random\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1) Add 20 new realistic domain sentences\n",
    "# -------------------------------------------------\n",
    "\n",
    "corpus += [\n",
    "    \"dns lookup fails intermittently causing slow page loads\",\n",
    "    \"sso login redirects in a loop after recent configuration change\",\n",
    "    \"ssl certificate expired users see security warning in browser\",\n",
    "    \"database connection pool exhausted under peak traffic\",\n",
    "    \"service health check failing pod keeps restarting in kubernetes\",\n",
    "    \"disk usage on server is 95 percent logs not rotating\",\n",
    "    \"cpu usage spikes to 100 percent after nightly batch job\",\n",
    "    \"cannot connect to vpn error 720 on windows\",\n",
    "    \"azure ad sync error duplicate attribute detected\",\n",
    "    \"password policy change forces reset but emails not sent\",\n",
    "    \"api returns 429 rate limit exceeded for valid clients\",\n",
    "    \"file upload fails with 413 payload too large\",\n",
    "    \"scheduled report job fails permission denied writing to s3\",\n",
    "    \"user account locked after multiple failed mfa attempts\",\n",
    "    \"mobile app crashes on startup after latest release\",\n",
    "    \"latency high between regions packet loss detected\",\n",
    "    \"redis cache miss rate increased after deployment\",\n",
    "    \"websocket disconnects frequently on unstable network\",\n",
    "    \"printer not found on network after ip change\",\n",
    "    \"time drift detected on server ntp not syncing\",\n",
    "]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2) Train test split\n",
    "# -------------------------------------------------\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(corpus)\n",
    "\n",
    "split = int(0.8 * len(corpus))\n",
    "train_texts = corpus[:split]\n",
    "test_texts = corpus[split:]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3) Tokenization helpers\n",
    "# -------------------------------------------------\n",
    "\n",
    "def tokenize(text):\n",
    "    return [\"<s>\"] + text.split() + [\"</s>\"]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4) Build vocab with min_count\n",
    "# -------------------------------------------------\n",
    "\n",
    "min_count = 1   # change later in Exercise 2\n",
    "\n",
    "freq = Counter()\n",
    "for sent in train_texts:\n",
    "    freq.update(tokenize(sent))\n",
    "\n",
    "vocab = {w for w, c in freq.items() if c >= min_count}\n",
    "vocab.add(\"<UNK>\")\n",
    "\n",
    "def replace_oov(tokens, vocab):\n",
    "    return [t if t in vocab else \"<UNK>\" for t in tokens]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5) Ngram counters\n",
    "# -------------------------------------------------\n",
    "\n",
    "def build_ngram_counts(texts, n, vocab):\n",
    "    ngram_counts = Counter()\n",
    "    context_counts = Counter()\n",
    "\n",
    "    for sent in texts:\n",
    "        tokens = replace_oov(tokenize(sent), vocab)\n",
    "\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ng = tuple(tokens[i:i+n])\n",
    "            ngram_counts[ng] += 1\n",
    "            context = ng[:-1]\n",
    "            context_counts[context] += 1\n",
    "\n",
    "    return ngram_counts, context_counts\n",
    "\n",
    "\n",
    "uni_counts, _ = build_ngram_counts(train_texts, 1, vocab)\n",
    "bi_counts, bi_ctx = build_ngram_counts(train_texts, 2, vocab)\n",
    "tri_counts, tri_ctx = build_ngram_counts(train_texts, 3, vocab)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6) Add-k probability\n",
    "# -------------------------------------------------\n",
    "\n",
    "def prob_addk(ngram, ngram_counts, context_counts, V, k=0.5):\n",
    "    if len(ngram) == 1:\n",
    "        return (ngram_counts[ngram] + k) / (sum(ngram_counts.values()) + k * V)\n",
    "\n",
    "    context = ngram[:-1]\n",
    "    return (ngram_counts[ngram] + k) / (context_counts[context] + k * V)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7) Perplexity\n",
    "# -------------------------------------------------\n",
    "\n",
    "def perplexity(texts, n, ngram_counts, context_counts, vocab, k=0.5):\n",
    "\n",
    "    V = len(vocab)\n",
    "    log_prob_sum = 0\n",
    "    N = 0\n",
    "\n",
    "    for sent in texts:\n",
    "        tokens = replace_oov(tokenize(sent), vocab)\n",
    "\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ng = tuple(tokens[i:i+n])\n",
    "            p = prob_addk(ng, ngram_counts, context_counts, V, k)\n",
    "\n",
    "            log_prob_sum += math.log(p)\n",
    "            N += 1\n",
    "\n",
    "    return math.exp(-log_prob_sum / N)\n",
    "\n",
    "\n",
    "pp_uni = perplexity(test_texts, 1, uni_counts, None, vocab)\n",
    "pp_bi = perplexity(test_texts, 2, bi_counts, bi_ctx, vocab)\n",
    "pp_tri = perplexity(test_texts, 3, tri_counts, tri_ctx, vocab)\n",
    "\n",
    "pp_uni, pp_bi, pp_tri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d102a386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_count | VocabSize |   OOV% |     PP_uni |      PP_bi |     PP_tri\n",
      "--------------------------------------------------------------------------\n",
      "        1 |       168 |  52.3% |     201.43 |     168.51 |     168.04\n",
      "        2 |        30 |  69.2% |       3.98 |       3.73 |       5.87\n",
      "        3 |        14 |  69.2% |       3.35 |       2.80 |       3.61\n",
      "        5 |         6 |  75.4% |       2.36 |       1.78 |       1.85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  168,\n",
       "  0.5230769230769231,\n",
       "  201.43152163872222,\n",
       "  168.5054504820778,\n",
       "  168.03898861922355),\n",
       " (2,\n",
       "  30,\n",
       "  0.6923076923076923,\n",
       "  3.976190035742321,\n",
       "  3.728033113080755,\n",
       "  5.867980977297841),\n",
       " (3,\n",
       "  14,\n",
       "  0.6923076923076923,\n",
       "  3.346262972145768,\n",
       "  2.7950536828537005,\n",
       "  3.614217671609578),\n",
       " (5,\n",
       "  6,\n",
       "  0.7538461538461538,\n",
       "  2.360129610683516,\n",
       "  1.7836713862003923,\n",
       "  1.8455029140131973)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====== Exercise 2: Change min_count (OOV threshold) and compare perplexity ======\n",
    "\n",
    "import random\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Train test split\n",
    "# ---------------------------\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(corpus)\n",
    "\n",
    "split = int(0.8 * len(corpus))\n",
    "train_texts = corpus[:split]\n",
    "test_texts = corpus[split:]\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Tokenization + OOV helpers\n",
    "# ---------------------------\n",
    "\n",
    "def tokenize(text):\n",
    "    return [\"<s>\"] + text.split() + [\"</s>\"]\n",
    "\n",
    "def replace_oov(tokens, vocab):\n",
    "    return [t if t in vocab else \"<UNK>\" for t in tokens]\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Build ngram counts\n",
    "# ---------------------------\n",
    "\n",
    "def build_ngram_counts(texts, n, vocab):\n",
    "    ngram_counts = Counter()\n",
    "    context_counts = Counter()\n",
    "\n",
    "    for sent in texts:\n",
    "        tokens = replace_oov(tokenize(sent), vocab)\n",
    "\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ng = tuple(tokens[i:i+n])\n",
    "            ngram_counts[ng] += 1\n",
    "            context = ng[:-1]\n",
    "            context_counts[context] += 1\n",
    "\n",
    "    return ngram_counts, context_counts\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Add-k probability\n",
    "# ---------------------------\n",
    "\n",
    "def prob_addk(ngram, ngram_counts, context_counts, V, k=0.5):\n",
    "    if len(ngram) == 1:\n",
    "        return (ngram_counts[ngram] + k) / (sum(ngram_counts.values()) + k * V)\n",
    "    context = ngram[:-1]\n",
    "    return (ngram_counts[ngram] + k) / (context_counts[context] + k * V)\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Perplexity\n",
    "# ---------------------------\n",
    "\n",
    "def perplexity(texts, n, ngram_counts, context_counts, vocab, k=0.5):\n",
    "    V = len(vocab)\n",
    "    log_prob_sum = 0.0\n",
    "    N = 0\n",
    "\n",
    "    for sent in texts:\n",
    "        tokens = replace_oov(tokenize(sent), vocab)\n",
    "\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ng = tuple(tokens[i:i+n])\n",
    "            p = prob_addk(ng, ngram_counts, context_counts, V, k)\n",
    "            log_prob_sum += math.log(p)\n",
    "            N += 1\n",
    "\n",
    "    return math.exp(-log_prob_sum / N)\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Run experiment for different min_count values\n",
    "# ---------------------------\n",
    "\n",
    "k_smooth = 0.5\n",
    "min_counts = [1, 2, 3, 5]  \n",
    "\n",
    "results = []\n",
    "\n",
    "for mc in min_counts:\n",
    "    # build vocab\n",
    "    freq = Counter()\n",
    "    for sent in train_texts:\n",
    "        freq.update(tokenize(sent))\n",
    "\n",
    "    vocab = {w for w, c in freq.items() if c >= mc}\n",
    "    vocab.add(\"<UNK>\")\n",
    "\n",
    "    # train ngrams\n",
    "    uni_counts, _ = build_ngram_counts(train_texts, 1, vocab)\n",
    "    bi_counts, bi_ctx = build_ngram_counts(train_texts, 2, vocab)\n",
    "    tri_counts, tri_ctx = build_ngram_counts(train_texts, 3, vocab)\n",
    "\n",
    "    # evaluate perplexity\n",
    "    pp_uni = perplexity(test_texts, 1, uni_counts, None, vocab, k=k_smooth)\n",
    "    pp_bi  = perplexity(test_texts, 2, bi_counts, bi_ctx, vocab, k=k_smooth)\n",
    "    pp_tri = perplexity(test_texts, 3, tri_counts, tri_ctx, vocab, k=k_smooth)\n",
    "\n",
    "    # report oov ratio on test set (helpful for explanation)\n",
    "    total_tokens = 0\n",
    "    oov_tokens = 0\n",
    "    for sent in test_texts:\n",
    "        toks = tokenize(sent)\n",
    "        total_tokens += len(toks)\n",
    "        oov_tokens += sum(1 for t in toks if t not in vocab)\n",
    "\n",
    "    oov_ratio = oov_tokens / total_tokens\n",
    "\n",
    "    results.append((mc, len(vocab), oov_ratio, pp_uni, pp_bi, pp_tri))\n",
    "\n",
    "# ---------------------------\n",
    "# 7)  print\n",
    "# ---------------------------\n",
    "\n",
    "print(f\"{'min_count':>9} | {'VocabSize':>9} | {'OOV%':>6} | {'PP_uni':>10} | {'PP_bi':>10} | {'PP_tri':>10}\")\n",
    "print(\"-\" * 74)\n",
    "\n",
    "for mc, vsize, oov_ratio, ppu, ppb, ppt in results:\n",
    "    print(f\"{mc:>9} | {vsize:>9} | {oov_ratio*100:>5.1f}% | {ppu:>10.2f} | {ppb:>10.2f} | {ppt:>10.2f}\")\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbf7f91",
   "metadata": {},
   "source": [
    "When I increased min_count, the vocabulary size dropped a lot and more words were treated as <UNK>, which increased the OOV rate. With min_count = 1, the vocabulary was large, but because the dataset is small, many n grams only appeared once. This caused data sparsity and led to very high perplexity on the test set.\n",
    "When I changed min_count to 2 and 3, rare words were removed from the vocabulary, which reduced sparsity and made the model generalize better. As a result, perplexity decreased significantly for all three models.\n",
    "With min_count = 5, the vocabulary became extremely small and most tokens in the test data were replaced with <UNK>. This further reduced perplexity, but it also means the model lost a lot of specific information about the text. This shows there is a trade off between keeping a richer vocabulary and reducing sparsity when selecting the OOV threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "012797e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168.11933369555558, 205.88947572965333)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====== Exercise 3: Backoff (trigram -> bigram -> unigram) with add-k smoothing ======\n",
    "\n",
    "import random\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Train test split\n",
    "# ---------------------------\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(corpus)\n",
    "\n",
    "split = int(0.8 * len(corpus))\n",
    "train_texts = corpus[:split]\n",
    "test_texts = corpus[split:]\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Tokenization + OOV\n",
    "# ---------------------------\n",
    "\n",
    "def tokenize(text):\n",
    "    return [\"<s>\"] + text.split() + [\"</s>\"]\n",
    "\n",
    "def replace_oov(tokens, vocab):\n",
    "    return [t if t in vocab else \"<UNK>\" for t in tokens]\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Build vocab\n",
    "# ---------------------------\n",
    "\n",
    "min_count = 1  # you can change this\n",
    "freq = Counter()\n",
    "for sent in train_texts:\n",
    "    freq.update(tokenize(sent))\n",
    "\n",
    "vocab = {w for w, c in freq.items() if c >= min_count}\n",
    "vocab.add(\"<UNK>\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Build ngram counts\n",
    "# ---------------------------\n",
    "\n",
    "def build_ngram_counts(texts, n, vocab):\n",
    "    ngram_counts = Counter()\n",
    "    context_counts = Counter()\n",
    "\n",
    "    for sent in texts:\n",
    "        tokens = replace_oov(tokenize(sent), vocab)\n",
    "\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ng = tuple(tokens[i:i+n])\n",
    "            ngram_counts[ng] += 1\n",
    "            context = ng[:-1]\n",
    "            context_counts[context] += 1\n",
    "\n",
    "    return ngram_counts, context_counts\n",
    "\n",
    "uni_counts, _ = build_ngram_counts(train_texts, 1, vocab)\n",
    "bi_counts, bi_ctx = build_ngram_counts(train_texts, 2, vocab)\n",
    "tri_counts, tri_ctx = build_ngram_counts(train_texts, 3, vocab)\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Add-k probability (base)\n",
    "# ---------------------------\n",
    "\n",
    "def prob_addk(ngram, ngram_counts, context_counts, V, k=0.5):\n",
    "    if len(ngram) == 1:\n",
    "        return (ngram_counts[ngram] + k) / (sum(ngram_counts.values()) + k * V)\n",
    "    context = ngram[:-1]\n",
    "    return (ngram_counts[ngram] + k) / (context_counts[context] + k * V)\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Backoff probability\n",
    "# ---------------------------\n",
    "\n",
    "def prob_backoff_addk(trigram, tri_counts, tri_ctx, bi_counts, bi_ctx, uni_counts, vocab, k=0.5):\n",
    "    \"\"\"\n",
    "    trigram is a tuple of length 3: (w1, w2, w3)\n",
    "    If trigram unseen -> backoff to bigram (w2,w3)\n",
    "    If bigram unseen -> backoff to unigram (w3,)\n",
    "    Always uses add-k smoothing at the chosen order.\n",
    "    \"\"\"\n",
    "    V = len(vocab)\n",
    "    w1, w2, w3 = trigram\n",
    "\n",
    "    # try trigram if context exists (seen)\n",
    "    tri_context = (w1, w2)\n",
    "    if tri_ctx[tri_context] > 0:\n",
    "        return prob_addk((w1, w2, w3), tri_counts, tri_ctx, V, k)\n",
    "\n",
    "    # backoff to bigram\n",
    "    bi_context = (w2,)\n",
    "    if bi_ctx[bi_context] > 0:\n",
    "        return prob_addk((w2, w3), bi_counts, bi_ctx, V, k)\n",
    "\n",
    "    # backoff to unigram\n",
    "    return prob_addk((w3,), uni_counts, None, V, k)\n",
    "\n",
    "# ---------------------------\n",
    "# 7) Perplexity for backoff trigram\n",
    "# ---------------------------\n",
    "\n",
    "def perplexity_backoff(test_texts, tri_counts, tri_ctx, bi_counts, bi_ctx, uni_counts, vocab, k=0.5):\n",
    "    log_prob_sum = 0.0\n",
    "    N = 0\n",
    "\n",
    "    for sent in test_texts:\n",
    "        tokens = replace_oov(tokenize(sent), vocab)\n",
    "\n",
    "        # Need trigram windows, so pad is already handled by <s> and </s>\n",
    "        for i in range(len(tokens) - 3 + 1):\n",
    "            tri = (tokens[i], tokens[i+1], tokens[i+2])\n",
    "            p = prob_backoff_addk(tri, tri_counts, tri_ctx, bi_counts, bi_ctx, uni_counts, vocab, k=k)\n",
    "            log_prob_sum += math.log(p)\n",
    "            N += 1\n",
    "\n",
    "    return math.exp(-log_prob_sum / N)\n",
    "\n",
    "# ---------------------------\n",
    "# 8) Compare PP: plain trigram vs backoff trigram\n",
    "# ---------------------------\n",
    "\n",
    "k_smooth = 0.5\n",
    "\n",
    "def perplexity_plain_trigram(test_texts, tri_counts, tri_ctx, vocab, k=0.5):\n",
    "    V = len(vocab)\n",
    "    log_prob_sum = 0.0\n",
    "    N = 0\n",
    "    for sent in test_texts:\n",
    "        tokens = replace_oov(tokenize(sent), vocab)\n",
    "        for i in range(len(tokens) - 3 + 1):\n",
    "            tri = (tokens[i], tokens[i+1], tokens[i+2])\n",
    "            p = prob_addk(tri, tri_counts, tri_ctx, V, k=k)\n",
    "            log_prob_sum += math.log(p)\n",
    "            N += 1\n",
    "    return math.exp(-log_prob_sum / N)\n",
    "\n",
    "pp_tri_plain = perplexity_plain_trigram(test_texts, tri_counts, tri_ctx, vocab, k=k_smooth)\n",
    "pp_tri_backoff = perplexity_backoff(test_texts, tri_counts, tri_ctx, bi_counts, bi_ctx, uni_counts, vocab, k=k_smooth)\n",
    "\n",
    "pp_tri_plain, pp_tri_backoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8424b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('login', 0.09090909090909091),\n",
       " ('expired', 0.030303030303030304),\n",
       " ('on', 0.030303030303030304),\n",
       " ('in', 0.030303030303030304),\n",
       " ('with', 0.030303030303030304)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====== Exercise 4: Top-5 next word predictions given a phrase (e.g., \"user cannot\") ======\n",
    "\n",
    "import random\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Train test split\n",
    "# ---------------------------\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(corpus)\n",
    "\n",
    "split = int(0.8 * len(corpus))\n",
    "train_texts = corpus[:split]\n",
    "test_texts = corpus[split:]\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Tokenization + OOV\n",
    "# ---------------------------\n",
    "\n",
    "def tokenize(text):\n",
    "    return [\"<s>\"] + text.split() + [\"</s>\"]\n",
    "\n",
    "def replace_oov(tokens, vocab):\n",
    "    return [t if t in vocab else \"<UNK>\" for t in tokens]\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Build vocab\n",
    "# ---------------------------\n",
    "\n",
    "min_count = 2   # you can change this based on Exercise 2\n",
    "freq = Counter()\n",
    "for sent in train_texts:\n",
    "    freq.update(tokenize(sent))\n",
    "\n",
    "vocab = {w for w, c in freq.items() if c >= min_count}\n",
    "vocab.add(\"<UNK>\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Build ngram counts\n",
    "# ---------------------------\n",
    "\n",
    "def build_ngram_counts(texts, n, vocab):\n",
    "    ngram_counts = Counter()\n",
    "    context_counts = Counter()\n",
    "\n",
    "    for sent in texts:\n",
    "        tokens = replace_oov(tokenize(sent), vocab)\n",
    "\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ng = tuple(tokens[i:i+n])\n",
    "            ngram_counts[ng] += 1\n",
    "            context = ng[:-1]\n",
    "            context_counts[context] += 1\n",
    "\n",
    "    return ngram_counts, context_counts\n",
    "\n",
    "uni_counts, _ = build_ngram_counts(train_texts, 1, vocab)\n",
    "bi_counts, bi_ctx = build_ngram_counts(train_texts, 2, vocab)\n",
    "tri_counts, tri_ctx = build_ngram_counts(train_texts, 3, vocab)\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Add-k probability\n",
    "# ---------------------------\n",
    "\n",
    "def prob_addk(ngram, ngram_counts, context_counts, V, k=0.5):\n",
    "    if len(ngram) == 1:\n",
    "        return (ngram_counts[ngram] + k) / (sum(ngram_counts.values()) + k * V)\n",
    "    context = ngram[:-1]\n",
    "    return (ngram_counts[ngram] + k) / (context_counts[context] + k * V)\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Backoff probability for next word\n",
    "# ---------------------------\n",
    "\n",
    "def next_word_prob_backoff(context_tokens, candidate, tri_counts, tri_ctx, bi_counts, bi_ctx, uni_counts, vocab, k=0.5):\n",
    "    \"\"\"\n",
    "    context_tokens: list of tokens (already OOV-replaced)\n",
    "    candidate: next token to score\n",
    "    backoff order: trigram -> bigram -> unigram\n",
    "    \"\"\"\n",
    "    V = len(vocab)\n",
    "\n",
    "    # try trigram if we have >=2 context tokens\n",
    "    if len(context_tokens) >= 2:\n",
    "        w1, w2 = context_tokens[-2], context_tokens[-1]\n",
    "        tri_context = (w1, w2)\n",
    "        if tri_ctx[tri_context] > 0:\n",
    "            return prob_addk((w1, w2, candidate), tri_counts, tri_ctx, V, k)\n",
    "\n",
    "    # backoff to bigram if we have >=1 context token\n",
    "    if len(context_tokens) >= 1:\n",
    "        w2 = context_tokens[-1]\n",
    "        bi_context = (w2,)\n",
    "        if bi_ctx[bi_context] > 0:\n",
    "            return prob_addk((w2, candidate), bi_counts, bi_ctx, V, k)\n",
    "\n",
    "    # backoff to unigram\n",
    "    return prob_addk((candidate,), uni_counts, None, V, k)\n",
    "\n",
    "# ---------------------------\n",
    "# 7) Top-k next word function\n",
    "# ---------------------------\n",
    "\n",
    "def topk_next_words(phrase, top_k=5, k_smooth=0.5, include_end_token=False):\n",
    "    \"\"\"\n",
    "    Returns list of (word, prob) for top_k next word predictions.\n",
    "    \"\"\"\n",
    "    # tokenize phrase (do NOT add <s> </s> around it, treat it as context only)\n",
    "    raw_tokens = phrase.split()\n",
    "    ctx = replace_oov(raw_tokens, vocab)\n",
    "\n",
    "    # candidates: vocab minus special start token\n",
    "    candidates = [w for w in vocab if w != \"<s>\"]\n",
    "    if not include_end_token:\n",
    "        candidates = [w for w in candidates if w != \"</s>\"]\n",
    "\n",
    "    scored = []\n",
    "    for w in candidates:\n",
    "        p = next_word_prob_backoff(ctx, w, tri_counts, tri_ctx, bi_counts, bi_ctx, uni_counts, vocab, k=k_smooth)\n",
    "        scored.append((w, p))\n",
    "\n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scored[:top_k]\n",
    "\n",
    "# ---------------------------\n",
    "# 8) Example usage\n",
    "# ---------------------------\n",
    "\n",
    "topk_next_words(\"user cannot\", top_k=5, k_smooth=0.5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aig230-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
